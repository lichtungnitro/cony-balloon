{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Evaluation Upon AI Dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table of Contents\n",
    "\n",
    "- **Read config file**: read the configuration file that defines the experiment method, group by method, blacklist filter, etc.\n",
    "- **Read dialogue messages**: read the dialogue file (in CSV format) containing the conversations to be analyzed.\n",
    "- **Start analysis**: Initiate the analysis process using the configured experiment and grouping methods.\n",
    "- **Deliver results and visualization**: visualize the obtained results in a suitable format for easy interpretation.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from IPython.display import HTML, display\n",
    "from loguru import logger\n",
    "import numpy as np\n",
    "from openpyxl.styles import Font, PatternFill\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import yaml\n",
    "\n",
    "load_dotenv(find_dotenv(\"../.env\"))\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logger.add(\"../log/runtime.log\", format=\"{time:YYYY-MM-DD} | {level} | {message}\", level=\"DEBUG\", rotation=\"12:00\",\n",
    "           retention=\"7 days\")\n",
    "preset = os.environ.get(\"PRESET\")\n",
    "\n",
    "with open(os.path.join(\"../conf/preset\", preset), \"r\") as ymlf:\n",
    "    config = yaml.safe_load(ymlf)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def allocate_lines(path: str) -> list:\n",
    "    with open(os.path.join(\"../conf\", path)) as reader:\n",
    "        lines = [o.strip() for o in reader.readlines() if o.strip()]\n",
    "    return lines"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def allocate_date(date_str: str) -> datetime:\n",
    "    return datetime.strptime(date_str, \"%Y-%m-%d\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def export_xlsx(path: str, dataframe: pd.DataFrame) -> None:\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H-%M-%S\")\n",
    "    with pd.ExcelWriter(os.path.join(\"../result\", f\"{timestamp} {path}\"), engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "        dataframe.to_excel(writer, sheet_name=\"Statistics\", engine=\"openpyxl\")\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets[\"Statistics\"]\n",
    "        worksheet.column_dimensions[\"A\"].width = 50"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "source, mode, depth, channel, lang, weight, normalize, resample = config[\"SOURCE\"], config[\"MODE\"], config[\"DEPTH\"], \\\n",
    "    config[\"CHANNEL\"], config[\"LANG\"], config[\"WEIGHT\"], config[\"NORMALIZE\"], config[\"RESAMPLE\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if mode in [\"control\", \"full\"]:\n",
    "    before_start, before_end, after_start, after_end = map(allocate_date, [config[\"VERSIONS\"][\"control\"][\"start\"],\n",
    "                                                                           config[\"VERSIONS\"][\"control\"][\"end\"],\n",
    "                                                                           config[\"VERSIONS\"][\"experiment\"][\"start\"],\n",
    "                                                                           config[\"VERSIONS\"][\"experiment\"][\"end\"]])\n",
    "elif mode == \"pop\":\n",
    "    before_start, before_end, after_start, after_end = map(allocate_date, [config[\"PERIODS\"][\"before\"][\"start\"],\n",
    "                                                                           config[\"PERIODS\"][\"before\"][\n",
    "                                                                               \"end\"],\n",
    "                                                                           config[\"PERIODS\"][\"after\"][\"start\"],\n",
    "                                                                           config[\"PERIODS\"][\"after\"][\"end\"]])\n",
    "else:\n",
    "    before_start, before_end, after_start, after_end = map(allocate_date, [config[\"VERSIONS\"][\"control\"][\"start\"],\n",
    "                                                                           config[\"VERSIONS\"][\"control\"][\"end\"],\n",
    "                                                                           config[\"VERSIONS\"][\"experiment\"][\"start\"],\n",
    "                                                                           config[\"VERSIONS\"][\"experiment\"][\"end\"]])\n",
    "    action = input(\"Press \\\"Enter\\\" to confirm using A/B control test date range, and press other keys to stop.\")\n",
    "    if action:\n",
    "        sys.exit(1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "expt_scope, ctrl_scope, bl_uid, bl_qname, bl_qid = map(\n",
    "    allocate_lines, [\n",
    "        config[\"VERSIONS\"][\"experiment\"][\"scope\"],\n",
    "        config[\"VERSIONS\"][\"control\"][\"scope\"],\n",
    "        config[\"BLACKLIST\"][\"uid\"],\n",
    "        config[\"BLACKLIST\"][\"qname\"],\n",
    "        config[\"BLACKLIST\"][\"qid\"]])"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_lst = []\n",
    "cols = [\"chatdate\", \"biztype\", \"session_id\", \"session_type\", \"uid\", \"resp_time\", \"input_type\", \"relationguid\", \"qname\",\n",
    "        \"expressid\", \"botexpid\", \"intentid\", \"intentname\", \"tomanualreason\", \"lang\"]\n",
    "for s in source:\n",
    "    if s.endswith(\".csv\"):\n",
    "        f = pd.read_csv(os.path.join(\"../src\", s), sep=\",\", index_col=False, encoding=\"utf-8\", dtype=\"unicode\",\n",
    "                        usecols=cols)\n",
    "        frame_lst.append(f)\n",
    "    elif s.endswith(\".xlsx\"):\n",
    "        f = pd.read_excel(os.path.join(\"../src\", s), index_col=False, engine=\"openpyxl\", dtype=\"unicode\", usecols=cols)\n",
    "        frame_lst.append(f)\n",
    "frame = pd.concat(frame_lst, ignore_index=True)\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[\"chatdate\"] = pd.to_datetime(frame[\"chatdate\"])\n",
    "frame = frame[frame[\"lang\"].isin(lang)]\n",
    "frame = frame[frame[\"biztype\"].isin(channel)]\n",
    "frame = frame[(~frame[\"uid\"].isin(bl_uid)) & (~frame[\"qname\"].isin(bl_qname)) & (~frame[\"relationguid\"].isin(bl_qid))]\n",
    "frame = frame[(frame[\"chatdate\"] >= before_start) & (frame[\"chatdate\"] < after_end)]\n",
    "frame[\"resp_time\"] = pd.to_datetime(frame[\"resp_time\"])\n",
    "frame[\"chatweek\"] = frame[\"chatdate\"].dt.isocalendar().week\n",
    "frame[\"chatmonth\"] = frame[\"chatdate\"].dt.month\n",
    "frame.sort_values(by=[\"session_id\", \"resp_time\"], ascending=True, inplace=True)\n",
    "frame[\"session_type\"] = frame[\"session_type\"].replace(\n",
    "    {\"机器\": \"Chatbot\", \"人工\": \"Agent\", \"供应商客服\": \"Supplier Agent\"})\n",
    "frame[\"expressid\"] = frame[\"relationguid\"] + \"-\" + frame[\"expressid\"]\n",
    "frame[\"botexpid\"] = frame[\"intentid\"] + \"-\" + frame[\"botexpid\"]\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if weight == \"weighted\":\n",
    "    rounds = frame.groupby(\"session_id\").size().reset_index(name=\"round\")\n",
    "    frame = frame.merge(rounds, on=\"session_id\")\n",
    "    if depth == \"session\":\n",
    "        frame.rename(columns={\"round\": \"weight\"}, inplace=True)\n",
    "    elif depth == \"message\":\n",
    "        frame[\"weight\"] = (1 / frame[\"round\"]).round(decimals=2)\n",
    "        frame.drop(\"round\", axis=1, inplace=True)\n",
    "        match normalize:\n",
    "            case \"minmax\":\n",
    "                scaler = MinMaxScaler()\n",
    "                frame[\"weight\"] = scaler.fit_transform(frame[[\"weight\"]])\n",
    "            case \"log\":\n",
    "                frame[\"weight\"] = np.log(frame[\"weight\"])\n",
    "frame.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if mode in [\"control\", \"full\"]:\n",
    "    expt_by = config[\"VERSIONS\"][\"experiment\"][\"by\"]\n",
    "    beta_frame = frame[(frame[\"chatdate\"] >= before_start) & (frame[\"chatdate\"] < before_end) & (\n",
    "        frame[expt_by].isin(expt_scope))].dropna(subset=expt_by)\n",
    "    if depth == \"session\" or weight in [\"last\", \"weighted\"]:\n",
    "        beta_frame.drop_duplicates(subset=\"session_id\", keep=\"last\", inplace=True)\n",
    "    beta_sessions = beta_frame[\"session_id\"].tolist()\n",
    "    beta_ssr = pd.DataFrame()\n",
    "    if weight in [\"equal\", \"last\"]:\n",
    "        beta_ssr = beta_frame.groupby([f\"chat{resample}\", \"session_type\"])[\"session_id\"].count().unstack(fill_value=0)\n",
    "        beta_ssr[\"Total\"] = beta_ssr[\"Agent\"] + beta_ssr[\"Chatbot\"]\n",
    "        beta_ssr[\"Total Diff\"] = (100 * beta_ssr[\"Total\"].diff() / beta_ssr[\"Total\"]).round(decimals=2)\n",
    "        beta_ssr[\"Prop\"] = (100 * beta_ssr[\"Total\"] / beta_frame.shape[0]).round(decimals=2)\n",
    "        beta_ssr[\"SSR\"] = (100 * beta_ssr[\"Chatbot\"] / beta_ssr[\"Total\"]).round(decimals=2)\n",
    "        beta_ssr[\"SSR Diff\"] = (100 * beta_ssr[\"SSR\"].diff() / beta_ssr[\"SSR\"]).round(decimals=2)\n",
    "    elif weight == \"weighted\":\n",
    "        beta_ssr = beta_frame.groupby([f\"chat{resample}\", \"session_type\"])[\"weight\"].sum().unstack(fill_value=0)\n",
    "        beta_ssr[\"Total\"] = beta_ssr[\"Agent\"] + beta_ssr[\"Chatbot\"]\n",
    "        beta_ssr[\"Total Diff\"] = (100 * beta_ssr[\"Total\"].diff() / beta_ssr[\"Total\"]).round(decimals=2)\n",
    "        beta_ssr[\"SSR\"] = (100 * beta_ssr[\"Chatbot\"] / beta_ssr[\"Total\"]).round(decimals=2)\n",
    "        beta_ssr[\"SSR Diff\"] = (100 * beta_ssr[\"SSR\"].diff() / beta_ssr[\"SSR\"]).round(decimals=2)\n",
    "    display(HTML(beta_ssr.to_html(notebook=True, max_rows=5)))\n",
    "    export_xlsx(\"Beta Version Performance.xlsx\", beta_ssr)\n",
    "\n",
    "    ctrl_by = config[\"VERSIONS\"][\"control\"][\"by\"]\n",
    "    alpha_frame = frame[\n",
    "        (frame[\"chatdate\"] >= after_start) & (frame[\"chatdate\"] < after_end) & (frame[ctrl_by].isin(ctrl_scope)) & (\n",
    "            ~frame[\"session_id\"].isin(beta_sessions))].dropna(\n",
    "        subset=ctrl_by)\n",
    "    alpha_ssr = pd.DataFrame()\n",
    "    if depth == \"session\" or weight in [\"last\", \"weighted\"]:\n",
    "        alpha_frame.drop_duplicates(subset=\"session_id\", keep=\"last\", inplace=True)\n",
    "    if weight in [\"equal\", \"last\"]:\n",
    "        alpha_ssr = alpha_frame.groupby([f\"chat{resample}\", \"session_type\"])[\"session_id\"].count().unstack(fill_value=0)\n",
    "        alpha_ssr[\"Total\"] = alpha_ssr[\"Agent\"] + alpha_ssr[\"Chatbot\"]\n",
    "        alpha_ssr[\"Total Diff\"] = (100 * alpha_ssr[\"Total\"].diff() / alpha_ssr[\"Total\"]).round(decimals=2)\n",
    "        alpha_ssr[\"Prop\"] = (100 * alpha_ssr[\"Total\"] / alpha_frame.shape[0]).round(decimals=2)\n",
    "        alpha_ssr[\"SSR\"] = (100 * alpha_ssr[\"Chatbot\"] / alpha_ssr[\"Total\"]).round(decimals=2)\n",
    "        alpha_ssr[\"SSR Diff\"] = (100 * alpha_ssr[\"SSR\"].diff() / alpha_ssr[\"SSR\"]).round(decimals=2)\n",
    "    elif weight == \"weighted\":\n",
    "        alpha_ssr = alpha_frame.groupby([f\"chat{resample}\", \"session_type\"])[\"weight\"].sum().unstack(fill_value=0)\n",
    "        alpha_ssr[\"Total\"] = alpha_ssr[\"Agent\"] + alpha_ssr[\"Chatbot\"]\n",
    "        alpha_ssr[\"Total Diff\"] = (100 * alpha_ssr[\"Total\"].diff() / alpha_ssr[\"Total\"]).round(decimals=2)\n",
    "        alpha_ssr[\"SSR\"] = (100 * alpha_ssr[\"Chatbot\"] / alpha_ssr[\"Total\"]).round(decimals=2)\n",
    "        alpha_ssr[\"SSR Diff\"] = (100 * alpha_ssr[\"SSR\"].diff() / alpha_ssr[\"SSR\"]).round(decimals=2)\n",
    "    display(HTML(alpha_ssr.to_html(notebook=True, max_rows=5)))\n",
    "    export_xlsx(\"Alpha Version Performance.xlsx\", alpha_ssr)\n",
    "    \n",
    "    # TODO: plot line chart and heatmap"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "if mode in [\"pop\", \"full\"]:\n",
    "    pop_by = config[\"PERIODS\"][\"by\"]\n",
    "\n",
    "    before_frame = frame[(frame[\"chatdate\"] >= before_start) & (frame[\"chatdate\"] < before_end)].dropna(subset=pop_by)\n",
    "    before_ssr = pd.DataFrame()\n",
    "    if depth == \"session\" or weight in [\"last\", \"weighted\"]:\n",
    "        before_frame.drop_duplicates(subset=\"session_id\", keep=\"last\", inplace=True)\n",
    "    if weight in [\"equal\", \"last\"]:\n",
    "        before_ssr = before_frame.groupby([pop_by, \"session_type\"])[\"session_id\"].count().unstack(fill_value=0)\n",
    "        before_ssr[\"Total\"] = before_ssr[\"Agent\"] + before_ssr[\"Chatbot\"]\n",
    "        before_ssr[\"Prop\"] = (100 * before_ssr[\"Total\"] / before_frame.shape[0]).round(decimals=2)\n",
    "        before_ssr[\"SSR\"] = (100 * before_ssr[\"Chatbot\"] / before_ssr[\"Total\"]).round(decimals=2)\n",
    "        before_ssr.sort_values(by=[\"Chatbot\", \"Prop\", \"SSR\"], ascending=False, inplace=True)\n",
    "    elif weight == \"weighted\":\n",
    "        before_ssr = before_frame.groupby([pop_by, \"session_type\"])[\"weight\"].sum().unstack(fill_value=0)\n",
    "        before_ssr[\"Total\"] = before_ssr[\"Agent\"] + before_ssr[\"Chatbot\"]\n",
    "        before_ssr[\"SSR\"] = (100 * before_ssr[\"Chatbot\"] / before_ssr[\"Total\"]).round(decimals=2)\n",
    "\n",
    "    after_frame = frame[(frame[\"chatdate\"] >= after_start) & (frame[\"chatdate\"] < after_end)].dropna(subset=pop_by)\n",
    "    after_ssr = pd.DataFrame()\n",
    "    if depth == \"session\" or weight in [\"last\", \"weighted\"]:\n",
    "        after_frame.drop_duplicates(subset=\"session_id\", keep=\"last\", inplace=True)\n",
    "    if weight in [\"equal\", \"last\"]:\n",
    "        after_ssr = after_frame.groupby([pop_by, \"session_type\"])[\"session_id\"].count().unstack(fill_value=0)\n",
    "        after_ssr[\"Total\"] = after_ssr[\"Agent\"] + after_ssr[\"Chatbot\"]\n",
    "        after_ssr[\"Prop\"] = (100 * after_ssr[\"Total\"] / after_frame.shape[0]).round(decimals=2)\n",
    "        after_ssr[\"SSR\"] = (100 * after_ssr[\"Chatbot\"] / after_ssr[\"Total\"]).round(decimals=2)\n",
    "        after_ssr.sort_values(by=[\"Chatbot\", \"Prop\", \"SSR\"], ascending=False, inplace=True)\n",
    "    elif weight == \"weighted\":\n",
    "        after_ssr = after_frame.groupby([pop_by, \"session_type\"])[\"weight\"].sum().unstack(fill_value=0)\n",
    "        after_ssr[\"Total\"] = after_ssr[\"Agent\"] + after_ssr[\"Chatbot\"]\n",
    "        after_ssr[\"SSR\"] = (100 * after_ssr[\"Chatbot\"] / after_ssr[\"Total\"]).round(decimals=2)\n",
    "\n",
    "    merge_ssr = before_ssr.merge(after_ssr, on=pop_by, how=\"outer\", suffixes=(\"(before)\", \"(after)\")).sort_values(\n",
    "        by=[\"Agent(after)\", \"SSR(after)\"], ascending=False)\n",
    "    merge_ssr[\"Total Fluctuation\"] = (\n",
    "            100 * (merge_ssr[\"Total(after)\"] - merge_ssr[\"Total(before)\"]) / merge_ssr[\"Total(before)\"]).round(2)\n",
    "    merge_ssr[\"SSR Fluctuation\"] = (\n",
    "            100 * (merge_ssr[\"SSR(after)\"] - merge_ssr[\"SSR(before)\"]) / merge_ssr[\"SSR(before)\"]).round(2)\n",
    "    display(HTML(merge_ssr.to_html(notebook=True, max_rows=5)))\n",
    "    export_xlsx(\"Merged Period-on-Period Performance.xlsx\", merge_ssr)\n",
    "    \n",
    "    # TODO: plot line chart and heatmap"
   ],
   "metadata": {
    "collapsed": false
   },
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
